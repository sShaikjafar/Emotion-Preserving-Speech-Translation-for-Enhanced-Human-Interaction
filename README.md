# ğŸ™ï¸ Emotion Preserving Speech Translation for Enhanced Human Interaction

A research-driven project that enhances cross-lingual communication by translating spoken language while preserving the speakerâ€™s emotional tone. It integrates emotion recognition and speech synthesis to ensure that translated output retains the original emotional contextâ€”enabling more natural and emotionally rich interactions.

## ğŸ“Œ Project Objectives

- Accurately translate speech from one language to another.
- Detect and preserve the emotional context of the speaker.
- Use synthesized speech to deliver translated content with original emotional cues.

## ğŸ› ï¸ Features

- ğŸ§ **Emotion Recognition** from speech input.
- ğŸŒ **Multilingual Translation** (e.g., English â†” Hindi).
- ğŸ—£ï¸ **Emotion-aware Speech Synthesis** for output.
- ğŸ§  Built using Machine Learning & Deep Learning models for accurate emotion detection and translation.

## ğŸ§ª Tech Stack

- **Programming Language**: Python
- **Libraries**:  
  - `transformers` (Hugging Face) â€“ for language models and translation  
  - `librosa`, `pyaudio` â€“ for audio processing  
  - `deepface`, `FER`, or similar â€“ for emotion recognition  
  - `gTTS`, `pyttsx3`, or `Tacotron2` â€“ for speech synthesis
- **Tools**: Jupyter Notebook, Google Colab, GitHub
