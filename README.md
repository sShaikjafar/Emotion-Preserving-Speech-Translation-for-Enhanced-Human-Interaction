# 🎙️ Emotion Preserving Speech Translation for Enhanced Human Interaction

A research-driven project that enhances cross-lingual communication by translating spoken language while preserving the speaker’s emotional tone. It integrates emotion recognition and speech synthesis to ensure that translated output retains the original emotional context—enabling more natural and emotionally rich interactions.

## 📌 Project Objectives

- Accurately translate speech from one language to another.
- Detect and preserve the emotional context of the speaker.
- Use synthesized speech to deliver translated content with original emotional cues.

## 🛠️ Features

- 🎧 **Emotion Recognition** from speech input.
- 🌐 **Multilingual Translation** (e.g., English ↔ Hindi).
- 🗣️ **Emotion-aware Speech Synthesis** for output.
- 🧠 Built using Machine Learning & Deep Learning models for accurate emotion detection and translation.

## 🧪 Tech Stack

- **Programming Language**: Python
- **Libraries**:  
  - `transformers` (Hugging Face) – for language models and translation  
  - `librosa`, `pyaudio` – for audio processing  
  - `deepface`, `FER`, or similar – for emotion recognition  
  - `gTTS`, `pyttsx3`, or `Tacotron2` – for speech synthesis
- **Tools**: Jupyter Notebook, Google Colab, GitHub
